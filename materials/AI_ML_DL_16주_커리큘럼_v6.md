# 인공지능(AI) · 머신러닝(ML) · 딥러닝(DL) 통합 강의 커리큘럼

## v6 — 2026학년도

---

# 강의 개요(Course Overview)

| 항목(Item) | 내용(Description) |
|---|---|
| 과목명(Course Title) | 인공지능(Artificial Intelligence) 이론과 실습 |
| 대상(Target) | 프로그래밍 경험이 있으나 파이썬(Python)은 처음인 전공 + 비전공 저학년 |
| 학기(Semester) | 15주 강의 + 1주 기말고사(Final Exam) |
| 수업 시간(Class Hours) | 주 1회, 150분(3시간 연강) |
| 도구(Tools) | Python, NumPy, Pandas, Scikit-learn, PyTorch, Matplotlib |
| 환경(Environment) | Google Colab / Jupyter Notebook |
| AI 사용 정책(AI Policy) | **과제·프로젝트:** AI 사용 허용 (프롬프트 + 검증 + 관찰 제출 필수) / **시험(중간·기말):** AI 사용 금지 |

---

# 수업 시간 구성: PART별 차별화(Differentiated Time Structure)

v5까지의 "이론 50분 → 따라하기 50분 → 응용 50분" 고정 포맷을 폐지한다.
**"따라하기 50분"은 Shift+Enter를 반복하는 수동적 학습**(Passive Learning)**이므로**, PART의 성격에 따라 시간 배분을 달리한다.

## PART 1: 파이썬 기초 (1~3주) — 코딩 중심

코딩 문법은 이론 강의로 50분을 채우기 어려우며, 억지로 채우면 지루해진다.
**짧은 브리핑 → 즉시 코딩 → 도전 과제** 구조로 운영한다.

| 구간(Block) | 시간(Time) | 성격(Type) | 설명(Description) |
|---|---|---|---|
| 개념 브리핑(Concept Briefing) | 20분 | 이론 | 핵심 문법을 시각화와 함께 짧고 굵게 설명 |
| 핑퐁 코딩(Ping-Pong Coding) | 30분 | 가이드 실습 | 교수자 시연(Ping) → 학생 즉시 변형(Pong), 한 블록씩 반복 |
| 휴식(Break) | 10분 | | |
| 도전 실습(Challenge Lab) | 50분 | 자기주도 실습 | 미니 프로젝트형 문제를 학생이 직접 풀기 |
| 휴식(Break) | 10분 | | |
| 심화 + 연습문제(Advanced + Exercises) | 30분 | 정리 | 응용 문제 풀이 + 오답 분석 + Q&A |

**핑퐁 코딩**(Ping-Pong Coding)**이란?**

교수자가 한 단계를 시연하면(Ping), 학생이 그 즉시 변형 과제를 작성한다(Pong).
예: 교수자가 `for`문으로 구구단을 보여주면 → 학생은 "별 찍기"를 스스로 작성한다.
Shift+Enter를 50분간 누르는 것이 아니라, **"보고 → 바로 변형"을 짧은 주기로 반복**하는 것이다.

**빈칸 채우기**(Fill-in-the-Blank) **노트북:**

완성된 코드를 실행하는 것이 아니라, 핵심 부분이 `___`로 비어 있는 노트북을 제공한다.
학생이 직접 채워야 실행된다. 이것이 능동적 학습(Active Learning)이다.

## PART 2-3: 데이터 분석 · ML 기초 (4~7주) — 이론-실습 균형

이론의 비중이 커지기 시작하나, 여전히 실전 데이터로 직접 구현하는 시간이 절반 이상이어야 한다.

| 구간(Block) | 시간(Time) | 성격(Type) | 설명(Description) |
|---|---|---|---|
| 이론 강의(Theory Lecture) | 40분 | 이론 | 개념·수식·시각화 (예: 결정 트리의 엔트로피 계산) |
| 가이드 실습(Guided Practice) | 20분 | 가이드 실습 | 핵심 코드만 함께 실행하며 이론과 연결 |
| 휴식(Break) | 10분 | | |
| 프로젝트 실습(Project Lab) | 50분 | 자기주도 실습 | 실전 데이터로 직접 구현 + 빈칸 채우기 노트북 |
| 휴식(Break) | 10분 | | |
| 발표 + 연습문제(Presentation + Exercises) | 20분 | 정리 | 학생 결과 공유 + Q&A |

## PART 4-5: ML 심화 · 딥러닝 (9~14주) — 이론 비중 증가

수식과 알고리즘 원리가 복잡해지므로 이론 시간을 확보하되, 구현 실습은 **단순 따라하기가 아닌 "빈칸 채우기 + 구조 설계"** 방식으로 운영한다.

| 구간(Block) | 시간(Time) | 성격(Type) | 설명(Description) |
|---|---|---|---|
| 이론 강의(Theory Lecture) | 50분 | 이론 | 수식과 원리 (예: 역전파 계산, 어텐션 메커니즘) |
| 휴식(Break) | 10분 | | |
| 구현 실습(Implementation Lab) | 50분 | 실습 | 빈칸 채우기 + 구조 설계 + 오류 수정(Debug) |
| 휴식(Break) | 10분 | | |
| 실험 + 연습문제(Experiment + Exercises) | 30분 | 정리 | 하이퍼파라미터 변경 실험 + 결과 비교 + Q&A |

---

# 주차별 활용 데이터 매핑(Weekly Dataset Mapping)

각 주차의 실습에 사용하는 **실전 데이터셋**(Real-World Dataset)**을** 미리 정한다.
학생들이 "교과서 예제"가 아닌 **뉴스에서 보던 실제 문제**를 다루게 한다.

| 주차(Week) | PART | 활용 데이터(Dataset) | 출처(Source) |
|---|---|---|---|
| 1-3주 | 파이썬 기초 | **코로나19**(COVID-19) **확진자 수** — 리스트, 딕셔너리, 함수 연습 | Our World in Data |
| 4주 | 데이터 분석 | **뉴욕 에어비앤비**(Airbnb NYC) — NumPy, Pandas 핵심 | Kaggle AB_NYC_2019 |
| 5주 | 데이터 시각화 | **뉴욕 에어비앤비**(Airbnb NYC) — EDA, 시각화, 탐색 | Kaggle AB_NYC_2019 |
| 6주 | ML 기초 | **심부전증**(Heart Failure) **예측** — 전처리, 교차 검증 | Kaggle Heart Failure |
| 7주 | ML 기초 | **LoL**(League of Legends) **승리 공식** — 분류, 평가 지표 | Kaggle LoL Ranked Games |
| 9주 | ML 심화 | **중고 자동차**(Used Car) **가격 예측** — 회귀, 앙상블 | Kaggle Used Cars |
| 10주 | ML 심화 | **고객 세그먼테이션**(Customer Segmentation) — K-Means, PCA | Kaggle Mall Customers |
| 11주 | DL 입문 | **MNIST 손글씨**(Handwritten Digit) — PyTorch 기초 | torchvision |
| 12주 | DL CNN | **CIFAR-10 이미지 분류** — CNN 구현 | torchvision |
| 13주 | DL RNN/NLP | **영화 리뷰 감성 분석**(Sentiment Analysis) — LSTM, Transformer | IMDB / HuggingFace |
| 14주 | DL 생성 | **MNIST 이미지 생성** — GAN, LLM API | torchvision |

---

# 참고 교재 및 자료(References)

| 교재(Textbook) | 역할(Role) |
|---|---|
| Bishop, *Pattern Recognition and Machine Learning* (2006) | 이론(Theory) 참고 |
| 권철민, *파이썬 머신러닝 완벽 가이드* (개정2판) | 실습(Practice) 참고 |
| GitHub: wikibook/ml-definitive-guide | 예제 코드(Example Code) 참고 |

---

# 주차별 상세 커리큘럼(Weekly Detailed Curriculum)

---

## PART 1: 파이썬 기초 (1~3주)

---

### 1주차 — 파이썬(Python) 기초 ①: AI 개론 + 변수, 자료형, 연산자

**학습 목표:** AI의 전체 그림을 이해하고, 파이썬의 기본 문법을 익힌다. AI 도구 사용의 윤리 원칙을 체득한다.

**활용 데이터:** 코로나19(COVID-19) 확진자 수

| 구간(Block) | 시간 | 내용(Content) |
|---|---|---|
| 개념 브리핑 (20분) | 20분 | **[도입] AI 시대의 코딩 윤리: "한 단계 더 들어가기" 토론 (25분)** |
| | | ① 두 학생의 과제 비교 — 같은 AI, 다른 결과 (5분) |
| | | ② AI 사용 3단계 모델: Level 0 → Level 1 → Level 2 (5분) |
| | | ③ 5개 사례 조별 토론 — 허용/경고/부정행위 판정 (10분) |
| | | ④ 학기 평가 원칙 공지 (5분) |
| | | **[이론] AI 개론 + 파이썬 소개 (추가 시간 활용)** |
| | | ⑤ AI → ML → DL의 관계와 역사 |
| | | ⑥ 왜 파이썬(Python)인가? — AI/데이터 분석의 표준 언어 |
| | | ⑦ Google Colab 환경 설정 및 Notebook 사용법 |
| 핑퐁 코딩 (30분) | 30분 | **파이썬 기본 문법** |
| | | Ping①: 변수(Variable)와 자료형(Data Type) 시연 → Pong: 코로나 확진자 수를 변수에 저장 |
| | | Ping②: 숫자형(Numeric) 연산 시연 → Pong: 확진자 증감률 계산 |
| | | Ping③: 문자열(String) 인덱싱/슬라이싱 시연 → Pong: 날짜 문자열 파싱 |
| | | Ping④: f-string 포맷팅 시연 → Pong: 확진자 수를 천 단위 쉼표로 출력 |
| 휴식 | 10분 | |
| 도전 실습 (50분) | 50분 | ① 코로나19 일별 확진자 데이터를 변수에 저장하고, 최댓값/평균 계산 |
| | | ② 문자열 처리 응용: 날짜 형식 변환, 지역명 파싱 |
| | | ③ f-string으로 분석 결과 보고서 형식 출력 |
| 휴식 | 10분 | |
| 심화 + 연습문제 (30분) | 30분 | ① 응용 문제 풀이 + 오답 분석 |
| | | ② 연습문제(10문항) — 프롬프트 + 검증 + 관찰 형식으로 제출 |
| | | ③ Q&A |

**시각화 자료:** AI/ML/DL 포함 관계 벤 다이어그램(Venn Diagram), 파이썬 자료형 계층도

**참고 프로젝트 파일:** `02-01 변수`, `02-02~03 숫자형`, `02-04~05 문자열`

---

### 2주차 — 파이썬(Python) 기초 ②: 자료구조 (리스트, 튜플, 딕셔너리, 집합)

**학습 목표:** 파이썬의 핵심 자료구조를 이해하고 활용한다.

**활용 데이터:** 코로나19 — 국가별/일별 확진자 수 데이터

| 구간(Block) | 시간 | 내용(Content) |
|---|---|---|
| 개념 브리핑 (20분) | 20분 | ① 리스트(List): 순서가 있는 변경 가능한 자료구조 |
| | | ② 튜플(Tuple): 순서가 있는 변경 불가능한 자료구조 |
| | | ③ 딕셔너리(Dictionary): 키-값 쌍의 자료구조 |
| | | ④ 집합(Set): 중복 없는 자료구조, 불리언(Boolean) |
| | | ⑤ 리스트 vs 튜플 vs 딕셔너리 vs 집합 비교표 시각화 |
| 핑퐁 코딩 (30분) | 30분 | Ping①: 리스트 생성/인덱싱/슬라이싱 → Pong: 코로나 일별 확진자 리스트 조작 |
| | | Ping②: 리스트 메서드(`append`, `sort`, `pop`) → Pong: 확진자 수 정렬, 상위 5일 추출 |
| | | Ping③: 딕셔너리 생성/접근 → Pong: 국가별 확진자 수 딕셔너리 구축 |
| | | Ping④: 집합 연산(`union`, `intersection`) → Pong: 확진자 급증 국가 vs 감소 국가 비교 |
| 휴식 | 10분 | |
| 도전 실습 (50분) | 50분 | ① 코로나19 데이터로 국가별 확진자 수 관리 프로그램 작성 (딕셔너리 활용) |
| | | ② 리스트로 7일 이동평균 직접 계산 (NumPy 없이!) |
| | | ③ 빈칸 채우기 노트북: 튜플 패킹/언패킹, 중첩 딕셔너리 |
| 휴식 | 10분 | |
| 심화 + 연습문제 (30분) | 30분 | ① 오류 수정(Debug) 실습: 일부러 틀린 코드를 주고 고치기 |
| | | ② 연습문제(10문항) + Q&A |

**시각화 자료:** 리스트 vs 튜플 vs 딕셔너리 vs 집합 비교표, 메모리 구조 도식

**참고 프로젝트 파일:** `02-06~07 리스트`, `02-08~09 튜플`, `02-10~11 딕셔너리`, `02-12~13 집합/불리언`

---

### 3주차 — 파이썬(Python) 기초 ③: 제어문, 함수, 컴프리헨션, 예외처리

**학습 목표:** 파이썬의 제어 흐름과 함수를 익히고, 실전 프로그래밍 능력을 갖춘다.

**활용 데이터:** 코로나19 — 기간별 추세 분석

| 구간(Block) | 시간 | 내용(Content) |
|---|---|---|
| 개념 브리핑 (20분) | 20분 | ① 조건문(if/elif/else): 비교 연산자, 논리 연산자 |
| | | ② 반복문(while/for): `range()`, `enumerate()`, `zip()`, `break`/`continue` |
| | | ③ 리스트/딕셔너리 컴프리헨션(Comprehension) |
| | | ④ 함수(Function): `def`, 매개변수, 반환값, `lambda`, `*args`/`**kwargs` |
| 핑퐁 코딩 (30분) | 30분 | Ping①: 조건문으로 짝수/홀수 판별 → Pong: 확진자 수가 1만 이상인 날 필터링 |
| | | Ping②: `for`문 + `enumerate()` → Pong: 코로나 확진자 수 변화율 계산 |
| | | Ping③: 컴프리헨션 예제 → Pong: 조건부 리스트 생성 (확진자 > 평균인 날만) |
| | | Ping④: 함수 정의 → Pong: 이동평균 계산 함수, 최댓값 찾기 함수 작성 |
| 휴식 | 10분 | |
| 도전 실습 (50분) | 50분 | ① 종합 미니 프로젝트: "코로나19 간이 분석기" — 기간 입력 → 통계 출력 → 추세 판단 |
| | | ② 예외처리(`try`/`except`) 활용: 잘못된 입력 대비 |
| | | ③ 빈칸 채우기 노트북: `lambda` + `map`/`filter` 활용 |
| 휴식 | 10분 | |
| 심화 + 연습문제 (30분) | 30분 | ① 오류 수정 실습: AI가 생성한 코드의 버그 찾기 |
| | | ② 연습문제(10문항) + Q&A |

**시각화 자료:** 제어문 흐름도(Flowchart), 함수 호출 스택 시각화

**참고 프로젝트 파일:** `02-14~15 if`, `02-16~17 while`, `02-18~19 for`, `02-20~21 Comprehension`, `02-22~23 함수`, `02-24~25 예외처리`, `02-26 라이브러리`

---

## PART 2: 데이터 분석 기초 (4~5주)

---

### 4주차 — 넘파이(NumPy)와 판다스(Pandas) 핵심

**학습 목표:** 데이터 분석의 기본 도구인 NumPy와 Pandas를 익힌다.

**활용 데이터:** 뉴욕 에어비앤비(Airbnb NYC 2019)

| 구간(Block) | 시간 | 내용(Content) |
|---|---|---|
| 이론 강의 (40분) | 40분 | ① 배열(Array)과 행렬(Matrix) 연산의 중요성 — 왜 `for`문 대신 NumPy인가? |
| | | ② 데이터프레임(DataFrame)과 시리즈(Series) 개념 |
| | | ③ 데이터 분석에서 Pandas가 하는 역할 |
| | | ④ 벡터화 연산(Vectorized Operation)과 브로드캐스팅(Broadcasting) 원리 |
| 가이드 실습 (20분) | 20분 | ① NumPy: `ndarray` 생성, 인덱싱, 슬라이싱, 브로드캐스팅 |
| | | ② Pandas: CSV 불러오기, `head()`, `info()`, `describe()` |
| 휴식 | 10분 | |
| 프로젝트 실습 (50분) | 50분 | **"뉴욕에서 방이 둘 딸린 집을 에어비앤비에 내놓으려 한다"** |
| | | ① `AB_NYC_2019.csv` 불러와서 구조 파악 |
| | | ② 2베드룸(`bedrooms == 2`) 필터링, 결측값 처리 |
| | | ③ 지역별(`neighbourhood_group`) 가격 통계 계산 |
| | | ④ 이상치 제거(`price > 1000` 제외) 전후 비교 |
| | | ⑤ **검증:** 필터링 전후 행 수 출력, `mean` vs `median` 차이 확인 |
| 휴식 | 10분 | |
| 발표 + 연습문제 (20분) | 20분 | ① 학생 2~3명 결과 발표: "적정 숙박료는 얼마인가?" |
| | | ② 연습문제(10문항) + Q&A |

**시각화 자료:** NumPy 배열 연산 과정 시각화, DataFrame 구조도

**참고 프로젝트 파일:** `01-01 ~ 01-09` 노트북 / 머신러닝 완벽가이드 1장

---

### 5주차 — 데이터 시각화(Data Visualization)와 탐색적 데이터 분석(EDA)

**학습 목표:** 데이터를 눈으로 보고 패턴을 발견하는 능력을 기른다.

**활용 데이터:** 뉴욕 에어비앤비(Airbnb NYC 2019) — 4주차 연속

| 구간(Block) | 시간 | 내용(Content) |
|---|---|---|
| 이론 강의 (40분) | 40분 | ① 왜 시각화(Visualization)가 중요한가? — 앤스콤의 사중주(Anscombe's Quartet) |
| | | ② 기술 통계(Descriptive Statistics): 평균(Mean), 분산(Variance), 상관계수(Correlation) |
| | | ③ 그래프 유형별 사용 시나리오: 언제 막대? 언제 산점도? 언제 박스플롯? |
| 가이드 실습 (20분) | 20분 | ① Matplotlib/Seaborn: 히스토그램, 산점도, 박스플롯, 히트맵 |
| | | ② Plotly: 대화형 그래프(Interactive Chart) |
| 휴식 | 10분 | |
| 프로젝트 실습 (50분) | 50분 | **실전 EDA: "뉴욕 에어비앤비 — 어디가 비싸고, 왜 비싼가?"** |
| | | ① 지역별 가격 분포 박스플롯 + 바이올린 플롯 |
| | | ② 위치(위도·경도) vs 가격 산점도 → 지도 위에 시각화 |
| | | ③ `room_type` × `neighbourhood_group` 교차 분석 히트맵 |
| | | ④ 상관계수 분석: 어떤 변수가 가격과 가장 관련이 높은가? |
| | | ⑤ **관찰 작성:** 구체적 수치와 패턴을 문장으로 기술 (일반론 금지) |
| 휴식 | 10분 | |
| 발표 + 연습문제 (20분) | 20분 | ① 학생 발표: "나의 EDA에서 발견한 가장 흥미로운 패턴" |
| | | ② 연습문제(10문항) + Q&A |

**시각화 자료:** 다양한 그래프 유형의 사용 시나리오 비교표, 앤스콤의 사중주

**참고 프로젝트 파일:** `02-01 ~ 02-04 시각화` 노트북 / `01-10 ~ 01-14 데이터 집계`

---

## PART 3: 머신러닝 기초 (6~7주)

---

### 6주차 — 머신러닝(ML) 워크플로우: 전처리(Preprocessing)와 교차 검증(Cross-Validation)

**학습 목표:** 머신러닝의 전체 파이프라인을 이해하고, 데이터 전처리와 모델 평가 기법을 익힌다.

**활용 데이터:** 심부전증(Heart Failure) 예측 데이터

| 구간(Block) | 시간 | 내용(Content) |
|---|---|---|
| 이론 강의 (40분) | 40분 | ① 머신러닝 개요: 지도학습(Supervised), 비지도학습(Unsupervised), 강화학습(Reinforcement) |
| | | ② ML 워크플로우: 데이터 수집 → 전처리 → 학습 → 평가 → 배포 |
| | | ③ 전처리: 스케일링(Scaling), 인코딩(Encoding), 결측값 처리(Imputation) |
| | | ④ 교차 검증(Cross-Validation): K-Fold, Stratified K-Fold |
| 가이드 실습 (20분) | 20분 | ① Scikit-learn: `fit()`, `predict()`, `transform()` |
| | | ② `train_test_split`, `cross_val_score` 사용법 |
| | | ③ `StandardScaler`, `LabelEncoder`, `OneHotEncoder` |
| 휴식 | 10분 | |
| 프로젝트 실습 (50분) | 50분 | **"데이터 분석으로 심부전증을 예방할 수 있을까?"** |
| | | ① 심부전증 데이터 탐색: 어떤 특성(Feature)이 있는가? |
| | | ② 전처리 파이프라인 구축: 수치형 스케일링 + 범주형 인코딩 |
| | | ③ 로지스틱 회귀(Logistic Regression)로 예측 모델 구축 |
| | | ④ 교차 검증으로 성능 평가 |
| | | ⑤ **검증:** 전처리 전후 정확도 비교 + `cross_val_score` 결과 출력 |
| 휴식 | 10분 | |
| 발표 + 연습문제 (20분) | 20분 | ① 학생 발표 + 연습문제(10문항) + Q&A |

**시각화 자료:** ML 워크플로우 전체 파이프라인 순서도

**참고:** 머신러닝 완벽가이드 2장 / Bishop Ch.1.1

---

### 7주차 — 분류(Classification): 결정 트리(Decision Tree), 평가 지표(Metrics), 랜덤 포레스트(Random Forest)

**학습 목표:** 분류의 핵심 알고리즘과 평가 방법, 앙상블의 기초를 이해한다.

**활용 데이터:** LoL(League of Legends) 랭크 게임 데이터

| 구간(Block) | 시간 | 내용(Content) |
|---|---|---|
| 이론 강의 (40분) | 40분 | ① 결정 트리: 정보 이득(Information Gain), 지니 불순도(Gini Impurity), 엔트로피(Entropy) |
| | | ② 평가 지표: 정확도(Accuracy), 정밀도(Precision), 재현율(Recall), F1 스코어(F1 Score) |
| | | ③ 오차 행렬(Confusion Matrix), ROC 곡선(ROC Curve), AUC |
| | | ④ 랜덤 포레스트: 앙상블(Ensemble)과 배깅(Bagging) 개념 |
| 가이드 실습 (20분) | 20분 | ① 결정 트리 학습 + 트리 시각화 |
| | | ② 오차 행렬 히트맵 + ROC 곡선 그리기 |
| 휴식 | 10분 | |
| 프로젝트 실습 (50분) | 50분 | **"이것만 하면 무조건 이긴다 — 데이터로 알아보는 LoL 승리 공식"** |
| | | ① LoL 데이터 탐색: 첫 타워, 첫 용, 첫 바론 등 게임 이벤트별 승률 분석 |
| | | ② 결정 트리로 승리 예측 모델 구축 |
| | | ③ 랜덤 포레스트로 성능 개선 + 특성 중요도(Feature Importance) 시각화 |
| | | ④ **결정 트리 vs 랜덤 포레스트 성능 비교** — 정확도, F1, ROC-AUC |
| | | ⑤ **관찰:** "바론 획득 시 승률 72.8%" 같은 구체적 수치 기반 분석 |
| 휴식 | 10분 | |
| 발표 + 연습문제 (20분) | 20분 | ① 중간고사 범위 안내 |
| | | ② 연습문제(10문항) + Q&A |

**시각화 자료:** 결정 트리 분기 과정, 오차 행렬 히트맵, 랜덤 포레스트 개념도

**참고:** 머신러닝 완벽가이드 3장, 4장 / Bishop Ch.1.5

---

## ✏ 8주차 — 중간고사(Midterm Exam)

| 구분(Category) | 내용(Content) |
|---|---|
| 시험 범위(Scope) | 1~7주차 전체 (파이썬 기초, NumPy/Pandas, 시각화/EDA, 전처리/교차검증, 결정트리/랜덤포레스트) |
| 시험 구성(Format) | 이론(50%) + 코딩 실습(50%) |
| 이론(Theory) | 객관식 + 단답형 + 서술형 (개념 이해, 알고리즘 원리) |
| 코딩 실습(Coding) | Colab 환경에서 데이터 전처리 → 모델 학습 → 평가 |
| AI 사용(AI Usage) | **금지** — 본인의 실력만으로 문제를 해결해야 한다 |
| 시간(Duration) | 150분 전체 사용 |

---

## PART 4: 머신러닝 심화 (9~10주)

---

### 9주차 — 앙상블(Ensemble) 심화와 회귀(Regression)

**학습 목표:** 고성능 부스팅 앙상블과 회귀 분석을 이해한다.

**활용 데이터:** 중고 자동차(Used Car) 가격 예측 데이터

| 구간(Block) | 시간 | 내용(Content) |
|---|---|---|
| 이론 강의 (50분) | 50분 | ① 부스팅(Boosting): GBM, XGBoost, LightGBM |
| | | ② 선형 회귀(Linear Regression): 최소제곱법(OLS), 경사 하강법(Gradient Descent) |
| | | ③ 과적합(Overfitting)과 규제(Regularization): 릿지(Ridge), 라쏘(Lasso), 엘라스틱넷(ElasticNet) |
| | | ④ 편향-분산 트레이드오프(Bias-Variance Tradeoff) |
| 휴식 | 10분 | |
| 구현 실습 (50분) | 50분 | **"자동으로 모은 중고 자동차 데이터를 분석해보자"** |
| | | ① 중고차 데이터 탐색 + 전처리 (연식, 주행거리, 연료 유형 등) |
| | | ② 선형 회귀 → Ridge → Lasso 순차 비교 |
| | | ③ XGBoost / LightGBM 학습 및 비교 |
| | | ④ `GridSearchCV`로 하이퍼파라미터 튜닝 |
| | | ⑤ **검증:** RMSE, R² 비교표 작성 + 특성 중요도 시각화 |
| 휴식 | 10분 | |
| 실험 + 연습문제 (30분) | 30분 | ① 규제 강도(α)를 변경하며 성능 변화 실험 |
| | | ② 연습문제(10문항) + Q&A |

**시각화 자료:** 배깅 vs 부스팅 비교도, 경사 하강법 애니메이션, 규제 효과 시각화

**참고:** 머신러닝 완벽가이드 4장, 5장 / Bishop Ch.1.1, Ch.3

---

### 10주차 — 비지도학습(Unsupervised Learning)과 신경망(Neural Network) 기초

**학습 목표:** 비지도학습의 핵심과 딥러닝의 기본 원리를 이해한다.

**활용 데이터:** 고객 세그먼테이션(Mall Customer Segmentation) 데이터

| 구간(Block) | 시간 | 내용(Content) |
|---|---|---|
| 이론 강의 (50분) | 50분 | ① K-평균(K-Means) 알고리즘 원리 |
| | | ② PCA(Principal Component Analysis): 차원 축소(Dimensionality Reduction) |
| | | ③ 퍼셉트론(Perceptron)과 다층 퍼셉트론(MLP) |
| | | ④ 활성화 함수(Activation Function): 시그모이드(Sigmoid), ReLU, 소프트맥스(Softmax) |
| 휴식 | 10분 | |
| 구현 실습 (50분) | 50분 | **"고객을 어떻게 분류할 것인가? — K-Means 고객 세그먼테이션"** |
| | | ① 고객 데이터 탐색: 연간 소득, 지출 점수 등 |
| | | ② K-Means 군집화 + 엘보우 방법(Elbow Method)으로 최적 K 결정 |
| | | ③ PCA로 고차원 데이터 2D 시각화 |
| | | ④ NumPy로 퍼셉트론 구현 (AND, OR, XOR 게이트) |
| | | ⑤ 순전파(Forward Propagation), 역전파(Backpropagation) 단계별 계산 |
| 휴식 | 10분 | |
| 실험 + 연습문제 (30분) | 30분 | ① K 값을 변경하며 군집 결과 비교 |
| | | ② 연습문제(10문항) + Q&A |

**시각화 자료:** K-Means 수렴 과정 애니메이션, PCA 전후 비교, 퍼셉트론 결정 경계

**참고:** 머신러닝 완벽가이드 6장, 7장 / Bishop Ch.5, Ch.9

---

## PART 5: 딥러닝 (11~14주)

---

### 11주차 — 파이토치(PyTorch) 입문과 심층 신경망(DNN)

**학습 목표:** 딥러닝 프레임워크인 PyTorch의 기본 사용법을 익힌다.

**활용 데이터:** MNIST 손글씨(Handwritten Digit)

| 구간(Block) | 시간 | 내용(Content) |
|---|---|---|
| 이론 강의 (50분) | 50분 | ① 왜 파이토치인가? — 동적 계산 그래프(Dynamic Computational Graph) |
| | | ② 텐서(Tensor) 연산과 자동 미분(Autograd) |
| | | ③ PyTorch 모델 구축: `nn.Module`, `nn.Linear`, `nn.Sequential` |
| | | ④ 손실 함수(Loss Function)와 옵티마이저(Optimizer) |
| 휴식 | 10분 | |
| 구현 실습 (50분) | 50분 | **빈칸 채우기 노트북 + MNIST 직접 구축** |
| | | ① 텐서 생성, 연산, GPU 전송 |
| | | ② Autograd로 경사 하강법 체험 |
| | | ③ PyTorch로 선형 회귀 구현 (빈칸 채우기) |
| | | ④ MNIST 손글씨 분류 DNN 스스로 구축 |
| | | ⑤ **검증:** 학습 손실(Loss) 그래프 그리기, 테스트 정확도 출력 |
| 휴식 | 10분 | |
| 실험 + 연습문제 (30분) | 30분 | ① 학습률(Learning Rate), 에폭(Epoch) 수를 변경하며 성능 변화 관찰 |
| | | ② 🎯 프로젝트 주제 선정 안내 |
| | | ③ 연습문제(10문항) + Q&A |

**시각화 자료:** 텐서 연산 과정도, PyTorch 모델 구조도

**참고:** PyTorch 공식 튜토리얼

---

### 12주차 — 합성곱 신경망(CNN: Convolutional Neural Network)

**학습 목표:** 이미지 인식의 핵심인 CNN의 원리와 구조를 이해한다.

**활용 데이터:** CIFAR-10 이미지 분류

| 구간(Block) | 시간 | 내용(Content) |
|---|---|---|
| 이론 강의 (50분) | 50분 | ① 합성곱 연산: 필터(Filter), 커널(Kernel), 스트라이드(Stride), 패딩(Padding) |
| | | ② 풀링(Pooling): 맥스풀링(Max Pooling), 평균풀링(Average Pooling) |
| | | ③ 대표 구조: LeNet → AlexNet → VGG → ResNet 발전사 |
| | | ④ 전이 학습(Transfer Learning) 개념 |
| 휴식 | 10분 | |
| 구현 실습 (50분) | 50분 | ① PyTorch로 CNN 구현: CIFAR-10 이미지 분류 (빈칸 채우기 노트북) |
| | | ② 필터 시각화(Filter Visualization)와 특성 맵(Feature Map) 확인 |
| | | ③ CNN 구조 변경 실험: 층 수, 필터 수 조정 → 정확도 변화 비교 |
| | | ④ 사전학습 모델(Pretrained Model) 전이 학습 도전 |
| 휴식 | 10분 | |
| 실험 + 연습문제 (30분) | 30분 | ① 🎯 프로젝트 중간 점검 |
| | | ② 연습문제(10문항) + Q&A |

**시각화 자료:** 합성곱 연산 과정 애니메이션, CNN 아키텍처 도식

**참고:** Bishop Ch.5 / PyTorch 공식 CNN 튜토리얼

---

### 13주차 — 순환 신경망(RNN), 자연어 처리(NLP), 트랜스포머(Transformer)

**학습 목표:** 시퀀스 데이터 처리와 현대 AI 핵심 아키텍처를 이해한다.

**활용 데이터:** IMDB 영화 리뷰 감성 분석

| 구간(Block) | 시간 | 내용(Content) |
|---|---|---|
| 이론 강의 (50분) | 50분 | ① 순환 신경망(RNN)과 기울기 소실 문제(Vanishing Gradient) |
| | | ② LSTM(Long Short-Term Memory)과 GRU(Gated Recurrent Unit) |
| | | ③ RNN의 한계 → 어텐션(Attention) 메커니즘의 등장 |
| | | ④ 트랜스포머(Transformer): 셀프 어텐션(Self-Attention), 인코더-디코더 |
| 휴식 | 10분 | |
| 구현 실습 (50분) | 50분 | ① PyTorch로 LSTM 감성 분석 (빈칸 채우기 노트북) |
| | | ② 어텐션 스코어 직접 계산 (NumPy) |
| | | ③ HuggingFace `transformers`로 NLP 파이프라인 활용 |
| | | ④ BERT/GPT 모델로 다양한 NLP 과제 실험 |
| 휴식 | 10분 | |
| 실험 + 연습문제 (30분) | 30분 | ① 다른 텍스트 데이터에 LSTM 또는 HuggingFace 모델 적용 |
| | | ② 연습문제(10문항) + Q&A |

**시각화 자료:** RNN 언폴딩 도식, LSTM 게이트 구조도, 어텐션 히트맵, 트랜스포머 아키텍처

**참고:** 머신러닝 완벽가이드 8장 / *Attention Is All You Need* (Vaswani et al., 2017)

---

### 14주차 — 생성형 AI(Generative AI)와 최신 트렌드

**학습 목표:** 생성 모델의 원리와 최신 AI 트렌드를 파악한다.

**활용 데이터:** MNIST 이미지 생성(GAN), LLM API

| 구간(Block) | 시간 | 내용(Content) |
|---|---|---|
| 이론 강의 (50분) | 50분 | ① 생성 모델(Generative) vs 판별 모델(Discriminative) |
| | | ② GAN: 생성자(Generator) vs 판별자(Discriminator) |
| | | ③ 확산 모델(Diffusion Model)과 이미지 생성 원리 |
| | | ④ 대규모 언어모델(LLM), 프롬프트 엔지니어링(Prompt Engineering), AI 윤리(Ethics) |
| 휴식 | 10분 | |
| 구현 실습 (50분) | 50분 | ① 간단한 GAN 구현: MNIST 이미지 생성 |
| | | ② LLM API 활용 (ChatGPT API / Claude API) |
| | | ③ 프롬프트 엔지니어링 기법 실습 |
| | | ④ 에폭별 생성 이미지 품질 변화 실험 |
| 휴식 | 10분 | |
| 실험 + 연습문제 (30분) | 30분 | ① 기말고사 범위 안내 |
| | | ② 연습문제(10문항) + Q&A |

**시각화 자료:** GAN 학습 과정 시각화, 생성 이미지 변화 과정

**참고:** 최신 논문 및 기술 블로그

---

## 15주차 — 🎯 프로젝트 발표(Project Presentation) 및 종합 정리

**학습 목표:** 학기 전체 내용을 종합 적용한 프로젝트를 발표하고, 기말고사를 준비한다.

| 구간(Block) | 시간 | 내용(Content) |
|---|---|---|
| 발표 ① (50분) | 50분 | ① 조별 또는 개인 프로젝트 발표 (팀당 10~15분) |
| | | ② 발표 구성: 문제 정의 → 데이터 탐색 → 모델 설계 → 결과 분석 |
| | | ③ 동료 평가 및 질의응답 |
| 휴식 | 10분 | |
| 발표 ② (50분) | 50분 | ① 나머지 팀/개인 발표 (계속) |
| | | ② 우수 프로젝트 시상 및 피드백 |
| 휴식 | 10분 | |
| 종합 정리 (30분) | 30분 | ① 학기 핵심 개념 마인드맵(Mind Map) 총정리 |
| | | ② ML/DL 분야 학습 로드맵(Learning Roadmap) 제시 |
| | | ③ 기말고사 범위 안내 + 자유 질의응답 |

---

## ✏ 16주차 — 기말고사(Final Exam)

| 구분(Category) | 내용(Content) |
|---|---|
| 시험 범위(Scope) | 1~14주차 전체 (단, 9~14주차 ML심화·DL 파트에 비중 ↑) |
| 시험 구성(Format) | 이론(50%) + 코딩 실습(50%) |
| 이론(Theory) | 객관식 + 단답형 + 서술형 (개념 이해, 알고리즘 원리, 구조 설명) |
| 코딩 실습(Coding) | Colab 환경에서 모델 설계 → 학습 → 평가 |
| AI 사용(AI Usage) | **금지** — 본인의 실력만으로 문제를 해결해야 한다 |
| 시간(Duration) | 150분 전체 사용 |

---

# 프로젝트 안내(Project Guidelines)

| 항목(Item) | 내용(Content) |
|---|---|
| 형태(Format) | 조별(3~4명) 또는 개인 선택 가능 |
| 주제(Topic) | 자유 주제 (아래 예시 참고) |
| 제출물(Deliverables) | Colab Notebook + 발표 자료 (PPT 또는 PDF) + **AI 사용 내역(프롬프트 로그)** |
| 발표(Presentation) | 팀당 10~15분 발표 + 5분 질의응답 |
| 공지 시기(Timeline) | 11주차 주제 선정, 12주차 중간 점검 |

## 프로젝트 주제 예시(Project Topic Examples)

| 분류(Category) | 주제 예시(Example) |
|---|---|
| 머신러닝(ML) | 캐글 데이터셋 활용 분류/회귀 (질병 예측, 가격 예측 등) |
| DL — 이미지 | CNN을 활용한 이미지 분류 (동물, 패션, 의료 이미지 등) |
| DL — 텍스트 | RNN/LSTM을 활용한 감성 분석 또는 텍스트 분류 |
| 트랜스포머(Transformer) | HuggingFace 모델을 활용한 NLP 과제 (요약, 번역, 감성 분석) |
| 생성형 AI(Generative AI) | GAN 이미지 생성 또는 LLM API 활용 창의적 응용 |

---

# 주차별 핵심 키워드 요약(Weekly Keyword Summary)

| 주차 | PART | 핵심 키워드(Keywords) | 활용 데이터(Dataset) |
|---|---|---|---|
| 1 | 파이썬 | AI 윤리 토론, AI 개론, 변수, 자료형, 문자열 | 코로나19 |
| 2 | 파이썬 | 리스트, 튜플, 딕셔너리, 집합 | 코로나19 |
| 3 | 파이썬 | 제어문, 함수, 컴프리헨션, 예외처리 | 코로나19 |
| 4 | 데이터 | NumPy, Pandas, 데이터프레임 | 에어비앤비 NYC |
| 5 | 데이터 | 시각화, EDA, Matplotlib, Seaborn, Plotly | 에어비앤비 NYC |
| 6 | ML 기초 | Scikit-learn, 전처리, 교차 검증 | 심부전증 |
| 7 | ML 기초 | 결정 트리, 평가 지표, 오차 행렬, 랜덤 포레스트 | LoL 승리 공식 |
| 8 | 시험 | ✏ 중간고사 (1~7주차) | — |
| 9 | ML 심화 | 앙상블(XGBoost, LightGBM), 회귀, 규제 | 중고 자동차 |
| 10 | ML 심화 | K-Means, PCA, 퍼셉트론, MLP, 역전파 | 고객 세그먼테이션 |
| 11 | DL | PyTorch, 텐서, 자동 미분, DNN | MNIST |
| 12 | DL | CNN, 합성곱, 전이 학습 | CIFAR-10 |
| 13 | DL | RNN, LSTM, NLP, 트랜스포머, 어텐션 | IMDB 감성 분석 |
| 14 | DL | 생성형 AI, GAN, LLM, AI 윤리 | MNIST 생성 |
| 15 | 종합 | 🎯 프로젝트 발표, 종합 정리, 학습 로드맵 | — |
| 16 | 시험 | ✏ 기말고사 (1~14주차) | — |

---

# v5 → v6 주요 변경 사항(Changelog: v5 → v6)

| 항목(Item) | v5 (기존) | v6 (변경) |
|---|---|---|
| 수업 시간 구조 | 전 주차 동일 (이론 50 + 따라하기 50 + 응용 50) | **PART별 차별화** — 파이썬(20+30+50+30), 데이터/ML(40+20+50+20), DL(50+50+30) |
| "따라하기 50분" | Shift+Enter 반복 수동 학습 | **핑퐁 코딩**(Ping-Pong Coding): 시연 → 즉시 변형, 짧은 주기 반복 |
| 실습 노트북 | 완성된 코드 제공 | **빈칸 채우기**(Fill-in-the-Blank) + **오류 수정**(Debug) 노트북 |
| 1주차 도입 | AI 개론만 진행 | **AI 윤리 토론 수업 추가** — "한 단계 더 들어가기" 원칙 체득 |
| 실습 데이터 | 범용 예제 데이터 | **실전 데이터 매핑** — 코로나19, 에어비앤비, LoL, 중고차 등 |
| AI 사용 정책 | 명시적 정책 없음 | **과제·프로젝트:** 3단계 평가 규칙(허용/경고/부정행위) + 프롬프트 제출 필수 / **시험:** AI 전면 금지 |
| 과제 제출 | 코드 + 결과 | 코드 + 결과 + **프롬프트 + 검증 + 관찰** |

---

# 평가 방식(Grading Policy)

| 항목(Item) | 비율(Weight) | 세부 내용(Details) |
|---|---|---|
| 출석(Attendance) | 10% | 결석 2회 이상 시 -1점 감점 |
| 과제(Assignment) | 10% | 매주 연습문제 + 코딩 과제 (10문항 이상), **프롬프트 + 검증 + 관찰 포함** |
| 중간고사(Midterm) | 30% | 8주차, 이론(50%) + 코딩 실습(50%) |
| 프로젝트(Project) | 20% | 15주차 발표, AI 사용 내역 제출 필수 |
| 기말고사(Final) | 30% | 16주차, 이론(50%) + 코딩 실습(50%) |

---

# AI 사용 평가 기준(AI Usage Evaluation Criteria)

> **적용 범위:** 매주 과제(Assignment), 프로젝트(Project), 수업 중 실습에 적용한다.
> **중간고사·기말고사에서는 AI 사용을 전면 금지한다.** 시험은 본인의 실력만으로 해결해야 한다.

## 허용(OK): 도구 활용 + 재현 가능한 검증 + 관찰

다음 중 2개 이상이 명확하면 "허용"으로 판정한다.

- 조건이 명시된 프롬프트 (규칙/제약/반복/seed 등)
- 실행 흔적 (코드, 출력, 그래프, 표)
- 관찰의 구체성 (위치·수치·패턴이 포함)
- 검증 문장 ("이 조건을 만족하는지 확인했다")

## 경고(Warning): 그럴듯하지만 근거가 약하다

- 프롬프트가 모호하거나 "코드 짜줘" 수준
- 결과 서술이 일반론 중심 (그래프/수치/관찰 부족)
- 실행은 했지만 검증 기준이 없음

## 부정행위(Misconduct): 사고 과정 자체를 AI에 위임

- "내 생각을 대신 써줘" 유형의 프롬프트
- 재현 가능한 실행 흔적이 없음
- 관찰이 아니라 정답 문장만 존재 (근거 없이 결론만)

---

# 수업 운영 방침(Course Policy)

1. 매 수업은 150분 연강(3시간)으로 진행하며, 교시 사이 10분 휴식을 둔다.
2. **PART별로 시간 배분을 달리한다** — 파이썬은 코딩 중심, DL은 이론 강화.
3. **핑퐁 코딩**(Ping-Pong Coding)**:** 교수자 시연 후 학생이 즉시 변형하는 능동적 실습을 기본으로 한다.
4. **빈칸 채우기**(Fill-in-the-Blank) **노트북:** 핵심 부분이 비어 있는 노트북을 제공하여 능동적 학습을 유도한다.
5. 모든 실습은 Google Colab 환경에서 진행하며, 코드와 결과를 함께 제출한다.
6. 매주 연습문제(10문항 이상)와 해답(Solution)을 제공한다.
7. 이론은 시각화(Visualization)를 통해 직관적으로 이해할 수 있도록 구성한다.
8. 수업 자료는 Markdown(md) + PDF 형태로 배포한다.
9. **AI 사용은 과제·프로젝트에서 허용하되**, 프롬프트 + 실행 흔적 + 검증 + 관찰을 함께 제출해야 한다. **중간·기말고사에서는 AI 사용을 금지한다.**

*본 커리큘럼은 수강생의 수준과 진도에 따라 유연하게 조정될 수 있다.*
